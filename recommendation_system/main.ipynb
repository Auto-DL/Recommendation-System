{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "75dbba10fc6620c626cd1fa2436ff69a4b43b4d8107ad1b0d4ae9140f5dc976d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import github as gh\n",
    "import bs4 as bs\n",
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AuthenticatedUser(login=None)\n"
     ]
    }
   ],
   "source": [
    "GITHUB_ACCESS_TOKEN=os.getenv('GITHUB_ACCESS_TOKEN')\n",
    "g=gh.Github(GITHUB_ACCESS_TOKEN)\n",
    "print(g.get_user())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29\n",
      "['_PaginatedListBase__elements', '_PaginatedListBase__fetchToIndex', '_PaginatedList__contentClass', '_PaginatedList__firstParams', '_PaginatedList__firstUrl', '_PaginatedList__headers', '_PaginatedList__list_item', '_PaginatedList__nextParams', '_PaginatedList__nextUrl', '_PaginatedList__parseLinkHeader', '_PaginatedList__requester', '_PaginatedList__reverse', '_PaginatedList__totalCount', '_Slice', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_couldGrow', '_fetchNextPage', '_getLastPageUrl', '_grow', '_isBiggerThan', '_reversed', 'get_page', 'reversed', 'totalCount']\n",
      "https://github.com/Z-yq/TensorflowTTS\n",
      "https://github.com/Kal213/StarGAN-Tutorial-Tensorflow-2.3\n",
      "https://github.com/lshug/first-order-model-tf\n",
      "https://github.com/veeenie/Tensorflow2\n",
      "https://github.com/hubertkarbowy/awd_lstm_tensorflow2\n",
      "https://github.com/sk981102/tensorflow_certificate\n",
      "https://github.com/boa50/tensorflow-styletransfer\n",
      "https://github.com/Zwyywz/TensorFlowLearningNotes\n",
      "https://github.com/Developik/tensorflow_image_model\n",
      "https://github.com/boa50/tensorflow-pix2pix\n",
      "https://github.com/Astro-Astre/tensorflow_merger_classifier\n",
      "https://github.com/huww98/torch-tensorflow-wrapper\n",
      "https://github.com/fadhil-code/TensorFlowProject3\n",
      "https://github.com/danilyef/ResNet-Tensorflow\n",
      "https://github.com/aysedemirel/TensorFlow-Pokemon-Course\n",
      "https://github.com/junyuchen245/Semi-supervised_FCM_Loss_for_Segmentation\n",
      "https://github.com/artset/image-to-illustration\n",
      "https://github.com/Vezqi/tf-emotes\n",
      "https://github.com/wchen777/ASL-recog\n",
      "https://github.com/The-bot-makers/Neural-Networks\n",
      "https://github.com/Moulishankar10/Employee-Salary-Classification\n",
      "https://github.com/AnkitaVyas77/AccidentDetection_SSD-Mobilenet\n",
      "https://github.com/stoguri11/SentAnalysis\n",
      "https://github.com/stevenohohohoh/Neural-Style-Transfer\n",
      "https://github.com/mhnaeem/emotion-detection\n",
      "https://github.com/nateyoungblood/rnn_titanic\n",
      "https://github.com/Tyler-Shamsuddoha/python-image-classifier-keras\n",
      "https://github.com/MalayAgr/MesoNet-DeepfakeDetection-API\n",
      "https://github.com/sidphbot/AutoKeras-ArcFaceHead\n"
     ]
    }
   ],
   "source": [
    "query='tensorflow language:python created:2021-04-01..2021-04-02'\n",
    "result=g.search_repositories(query)\n",
    "print(result.totalCount)\n",
    "print(dir(result))\n",
    "for repository in result:\n",
    "    # print(dir(repository))\n",
    "    print(repository.html_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/Tyler-Shamsuddoha/python-image-classifier-keras'\n",
    "url2='https://github.com/bamblebam/image-classification-rps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [./\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "options=Options()\n",
    "options.headless=True\n",
    "driver=webdriver.Chrome(ChromeDriverManager(path='./').install(),options=options)\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=driver.find_element_by_xpath(\"//*[@class='Details-content--hidden-not-important js-navigation-container js-active-navigation-container d-md-block']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue=list()\n",
    "full_list=list()\n",
    "links_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links=table.find_elements_by_tag_name('a')\n",
    "# print(len(links))\n",
    "# for link in links:\n",
    "#     href=link.get_attribute('href')\n",
    "#     if 'tree' in href or '.py' in href:\n",
    "#         stack.append(href)\n",
    "\n",
    "# driver.get(url2)\n",
    "# table=driver.find_element_by_xpath(\"//*[@class='Details-content--hidden-not-important js-navigation-container js-active-navigation-container d-md-block']\")\n",
    "# links=table.find_elements_by_tag_name('a')\n",
    "# for link in links:\n",
    "#     href=link.get_attribute('href')\n",
    "#     if '/tree/' in href or '.py' in href:\n",
    "#         stack.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_queue(links):\n",
    "    for link in links:\n",
    "        href=link.get_attribute('href')\n",
    "        if href in links_list:\n",
    "            return\n",
    "        if '/tree/' in href or '.py' in href:\n",
    "            links_list.append(href)\n",
    "            queue.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_through_files(link):\n",
    "    if '/tree/' in link:\n",
    "        driver.get(link)\n",
    "        time.sleep(2.5)\n",
    "        table=driver.find_element_by_xpath(\"//*[@class='Details-content--hidden-not-important js-navigation-container js-active-navigation-container d-block']\")\n",
    "        links=table.find_elements_by_tag_name('a')\n",
    "        push_to_queue(links)\n",
    "    elif '.py' in link:\n",
    "        driver.get(link)\n",
    "        time.sleep(2.5)\n",
    "        full_list.append(link)\n",
    "        #preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs():\n",
    "    while queue:\n",
    "        link=queue.pop(0)\n",
    "        search_through_files(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_relevant_links(url):\n",
    "    links_list.append(url)\n",
    "    driver.get(url)\n",
    "    table=driver.find_element_by_xpath(\"//*[@class='Details-content--hidden-not-important js-navigation-container js-active-navigation-container d-md-block']\")\n",
    "    links=table.find_elements_by_tag_name('a')\n",
    "    for link in links:\n",
    "        href=link.get_attribute('href')\n",
    "        if '/tree/' in href or '.py' in href:\n",
    "            links_list.append(href)\n",
    "            queue.append(href)\n",
    "    bfs()\n",
    "    print(\"Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ended\n"
     ]
    }
   ],
   "source": [
    "res=get_all_relevant_links('https://github.com/Z-yq/TensorflowTTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://github.com/Z-yq/TensorflowTTS/blob/main/fastspeech_extract_features.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/run-test.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/tacotron_extract_features.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/train_acoustic.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/train_vocoder.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/dataloaders/fastspeech_dataloader.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/dataloaders/tacotron_dataloader.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/dataloaders/vocoder_dataloader.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/__init__.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/conformer.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/fastspeech.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/model.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/positional_encoding.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/switchnorm.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/tacotron2.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/vocoder.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/models/weight_norm.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/synthesizer/synthesizer_fastspeech.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/synthesizer/synthesizer_tacotron.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/trainer/fastspeech_trainer.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/trainer/tacotron_trainer.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/trainer/vocoder_trainer.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/decoder.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/normalize.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/plot.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/speech_featurizers.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/stft.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/text_featurizers.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/tools.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/user_config.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/utils/utils.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/fastspeech_extract_features.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/run-test.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/tacotron_extract_features.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/train_acoustic.py\nhttps://github.com/Z-yq/TensorflowTTS/blob/main/train_vocoder.py\n"
     ]
    }
   ],
   "source": [
    "for i in full_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36 31\n"
     ]
    }
   ],
   "source": [
    "list_set=set(full_list)\n",
    "print(len(full_list),len(list_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}